{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize, special\n",
    "\n",
    "F = np.array([[1.0000, 0.1000],\n",
    "              [0, 1.0000]])\n",
    "\n",
    "G = np.array([[0.0050],\n",
    "              [0.1000]])\n",
    "\n",
    "C = np.array([[1, 0]])\n",
    "\n",
    "D = 0\n",
    "Gain = np.array([16.0302, 5.6622])\n",
    "\n",
    "L = np.array([[0.9902],\n",
    "              [0.9892]])\n",
    "safex = [26,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=14\n",
    "inputs = np.random.normal(0, 1, k)\n",
    "input_len=len(inputs)\n",
    "X = np.zeros((2, input_len + 1))\n",
    "Xe = np.zeros((2, input_len + 1))\n",
    "e = np.zeros((2, input_len))\n",
    "U = np.zeros((1,input_len))\n",
    "Y = np.zeros((1,input_len))\n",
    "r = np.zeros((1,input_len))\n",
    "z = np.zeros((1,input_len))\n",
    "S = np.zeros((input_len))\n",
    "n1 = np.random.normal(0,0.01, [1, input_len])      \n",
    "n2 = np.random.normal(0,0.001, [2, input_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_len):\n",
    "    e[:, i] = X[:, i] - Xe[:, i]\n",
    "    U[:,i] = -(Gain @ Xe[:, i])\n",
    "    X[:, i+1] = F @ X[:, i] + G @ U[:, i] + n2[:, i]\n",
    "    Y[:,i] = C @ X[:, i] + n1[:,i]\n",
    "    r[:,i] = Y[:,i] - C @ Xe[:, i]\n",
    "    Xe[:, i+1] = F @ Xe[:, i] + G @ U[:,i] + L @ r[:,i]\n",
    "covn_r=np.cov(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attackK= [0, 0.04155838 , 0.63838859 , 1.75426837 ,2.44935936 , 3.6651983 , 5.16561739 , 6.95368618 , 9.11716362 ,11.67267658 ,14.29706254, 17.41085821  ,0.       ,   0.    ]\n",
    "k=len(attackK)\n",
    "attack2K = [-30.971675   ,-30.971675  ,  -1.11684483 ,-30.90514398, -28.29714574 , -28.61888554, -28.91105434, -29.17567371, -29.41469648, -29.21724115 , -28.49741602 , 30.971675,     0.     ,      0. ]\n",
    "k1=len(attack2K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.normal(0, 1, k)\n",
    "input_len=len(inputs)\n",
    "Xk = np.zeros((2, input_len + 1))\n",
    "Xek = np.zeros((2, input_len + 1))\n",
    "ek = np.zeros((2, input_len))\n",
    "Uk = np.zeros((1,input_len))\n",
    "Uak = np.zeros((1,input_len))\n",
    "Yk = np.zeros((1,input_len))\n",
    "rk = np.zeros((1,input_len))\n",
    "covn_eK = np.zeros((2, 2))\n",
    "covn_rK = np.zeros((2, 2))\n",
    "zk = np.zeros((1,input_len))\n",
    "Sk = np.zeros((input_len))\n",
    "n1 = np.random.normal(0,0.01, [1, input_len])      \n",
    "n2 = np.random.normal(0,0.001, [2,input_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuek=[]\n",
    "mzk=[]\n",
    "bias=4\n",
    "for i in range(input_len):\n",
    "    ek[:, i] = Xk[:, i] - Xek[:, i]\n",
    "    Uk[:,i] = -(Gain @ Xek[:, i])\n",
    "    Uak[:,i] = -(Gain @ Xek[:, i])+attack2K[i]\n",
    "    Xk[:, i+1] = F @ Xk[:, i] + G @ Uak[:, i] + n2[:, i]\n",
    "    Yk[:,i] = C @ Xk[:, i] + n1[:,i] + attackK[i]\n",
    "    rk[:,i] = Yk[:,i] - C @ Xek[:, i]\n",
    "    Xek[:, i+1] = F @ Xek[:, i] + G @ Uk[:,i] + L @ rk[:,i]\n",
    "    zk[:,i] = rk[:,i].T * covn_r * rk[:,i]\n",
    "    residuek.append(rk[:,i])\n",
    "    mzk.append(zk[:,i])\n",
    "    Sk[i] = max((Sk[i-1] + zk[:,i] - bias), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.mean(np.array(mzk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def discrete_frame(Sk,N,th):\n",
    "        delSi = 2*th/(2*N-1)\n",
    "        Ek=np.zeros((len(Sk)))\n",
    "        for i in range(len(Sk)):\n",
    "            if Sk[i]<delSi[i]/2:\n",
    "                Ek[i]=0\n",
    "            elif Sk[i]>=th[i]:\n",
    "                Ek[i]=N\n",
    "            else :\n",
    "                Ek[i]=math.ceil(math.floor(Sk[i]/(delSi[i]/2))/2)\n",
    "        return Ek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuek=np.absolute(np.array(residuek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_mean=np.array([])\n",
    "for i in range(len(residuek)):\n",
    "    sums=0\n",
    "    for j in range(i+1):\n",
    "        sums+=residuek[j]\n",
    "    mean=sums/(j+1)\n",
    "    r_mean=np.append(r_mean,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00345009, 0.05337163, 0.07635245, 0.18199853, 0.16500704,\n",
       "       0.15223018, 0.14443103, 0.1386415 , 0.13745976, 0.1499943 ,\n",
       "       0.13696959, 0.14167598, 1.69303926, 1.78586384])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(r_mean>0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "import scipy.special as special\n",
    "from scipy import special, optimize\n",
    "def markov_transition(N, th, bias):\n",
    "    temp = np.zeros((N+1, N+1))\n",
    "    for i in range(1,N+1):\n",
    "        for j in range(1,N+1):\n",
    "            if j == 1 & i <= N:\n",
    "                temp[i, j] = Tx(1-i, th, bias, N)\n",
    "            elif j > 1 & j < N+1 & i <= N:\n",
    "                temp[i, j] = Px(j-i, th, bias, N)\n",
    "            elif j == N+1 & i<=N:\n",
    "                temp[i, j] = 1 - Tx(N-i, th, bias, N)\n",
    "            elif i == N+1 & j < N+1:\n",
    "                temp[i, j] = 0\n",
    "            else:\n",
    "                temp[i, j] = 1\n",
    "    P = temp\n",
    "    return P\n",
    "\n",
    "def Px(x, th, bias, N):\n",
    "    delSi = 2*th/(2*N-1)\n",
    "    z1 = np.max(x*delSi + 0.5*delSi + bias, 0)\n",
    "    p1 = special.gammainc(m/2, z1/2)\n",
    "    z2 = np.max(x*delSi - 0.5*delSi + bias, 0)\n",
    "    p2 = special.gammainc(m/2, z2/2)\n",
    "    p = p1-p2\n",
    "    return p\n",
    "def Tx(x, th, bias, N):\n",
    "    delSi = 2*th/(2*N-1)\n",
    "    z = np.max(x*delSi + 0.5*delSi + bias, 0)\n",
    "    t = special.gammainc(m/2, z/2)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization():\n",
    "    \n",
    "    def __init__(self,params,m,N,Ek):\n",
    "        self.params=params.T\n",
    "        self.threshold=params[:,0]\n",
    "        self.bias=params[:,1]\n",
    "        self.m=m\n",
    "        self.N=N\n",
    "        self.Ek=Ek\n",
    "\n",
    "    def gradient(self):\n",
    "        state=self.Ek\n",
    "        x=np.zeros((len(state)))\n",
    "        z=np.zeros((len(state)))\n",
    "        t=np.zeros((len(state)))\n",
    "        dt_dth=np.zeros((len(state)))\n",
    "        dt_dbias=np.zeros((len(state)))\n",
    "        for i in range(len(state)):\n",
    "            x[i]=self.N-1-state[i]\n",
    "            delSi = 2 * self.threshold[i] / (2 * self.N - 1)\n",
    "            z[i] = np.maximum(x[i] * delSi + 0.5 * delSi + self.bias[i], 0)\n",
    "            t[i] = 1 - special.gammainc(m / 2, z[i]/ 2)\n",
    "            dt_dth[i] = 0.5 * z[i] * np.exp(-z[i] / 2) * x[i] / (2 *self.N - 1)\n",
    "            dt_dbias[i] = 0.5 * z[i] * np.exp(-z[i] / 2)\n",
    "        return np.array([-dt_dth, -dt_dbias])\n",
    "\n",
    "    def adam_optimizer(self,learning_rate=0.8, beta1=0.9, beta2=0.999, epsilon=1e-8, num_iterations=2):\n",
    "        p = np.zeros_like(self.params)\n",
    "        v = np.zeros_like(self.params)\n",
    "\n",
    "        for t in range(1,num_iterations+1):\n",
    "            gradient = self.gradient()\n",
    "            p = beta1 * p + (1 - beta1) * gradient\n",
    "            v = beta2 * v + (1 - beta2) * (gradient ** 2)\n",
    "            p_hat = p / (1 - beta1 ** t)\n",
    "            v_hat = v / (1 - beta2 ** t)\n",
    "            self.params += learning_rate * p_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RLEnvironment():\n",
    "    def __init__(self, num_states,cusum,residual,action,N):\n",
    "        self.num_states = num_states\n",
    "        self.cusum = cusum\n",
    "        self.next_cusum=cusum\n",
    "        self.residual = residual\n",
    "        self.threshold = action[:,0]\n",
    "        self.bias=action[:,1]\n",
    "        self.absorb=N\n",
    "        self.current_state = None\n",
    "        \n",
    "    def discrete_frame(self):\n",
    "        delSi = 2*self.threshold/(2*self.absorb-1)\n",
    "        Ek=np.zeros((len(self.next_cusum)))\n",
    "        for i in range(len(self.next_cusum)):\n",
    "            if self.next_cusum[i]<delSi[i]/2:\n",
    "                Ek[i]=0\n",
    "            elif self.next_cusum[i]>=self.threshold[i]:\n",
    "                Ek[i]=self.absorb\n",
    "            else :\n",
    "                Ek[i]=math.ceil(math.floor(self.next_cusum[i]/(delSi[i]/2))/2)\n",
    "        return Ek\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_state = self.discrete_frame()\n",
    "        return self.current_state\n",
    "    \n",
    "    def calculate_reward(self,i):\n",
    "        # Calculate reward based on attack detection condition\n",
    "        if self.residual[i]>0.01 and self.cusum[i]> self.threshold[i]:\n",
    "            return 10\n",
    "        elif self.residual[i]<0.01 and self.cusum[i]<self.threshold[i]:\n",
    "            return 1\n",
    "        return -10\n",
    "\n",
    "    def step(self):\n",
    "        self.next_cusum=self.cusum-self.bias\n",
    "        next_state = self.discrete_frame()\n",
    "        return next_state,self.next_cusum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "N=10\n",
    "learning_rate=0.5\n",
    "threshold=np.ones((len(Sk),1))*6\n",
    "bias=np.ones((len(Sk),1))*4\n",
    "action = np.concatenate((threshold,bias),axis=1)\n",
    "Ek=discrete_frame(Sk,N,threshold)\n",
    "optimizer=Optimization(action,m,N,Ek)\n",
    "env = RLEnvironment(len(Sk),Sk,r_mean,action,N)\n",
    "num_episodes=10\n",
    "Q_values = np.zeros((num_episodes, len(Ek)))\n",
    "final_action=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state = env.reset()  # Reset the environment\n",
    "    for i in range(len(Sk)):\n",
    "        \n",
    "        reward = env.calculate_reward(i)\n",
    "        \n",
    "        if episode>0:\n",
    "            Q_values[episode, i] = reward + learning_rate*Q_values[episode-1,i]S\n",
    "        \n",
    "        \n",
    "    next_state,next_cusum = env.step()\n",
    "    action=optimizer.adam_optimizer()\n",
    "    final_action.append(np.copy(action))\n",
    "    optimizer.Ek=next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "        -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "        -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "       [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "        -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "        -2.09801235, -2.09801235, -2.09801235, -2.09801235]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_action[np.argmax(np.mean(Q_values,axis=1))]#optimal threshold and bias array for each cusum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.42227368, 4.42227368, 4.42227368, 4.42227368, 4.42227368,\n",
       "         4.42227368, 4.42227368, 4.42227368, 4.42227368, 4.42227368,\n",
       "         4.42227368, 4.42227368, 4.42227368, 4.42227368],\n",
       "        [2.42227325, 2.42227325, 2.42227325, 2.42227325, 2.42227325,\n",
       "         2.42227325, 2.42227325, 2.42227325, 2.42227325, 2.42227325,\n",
       "         2.42227325, 2.42227325, 2.42227325, 2.42227325]]),\n",
       " array([[2.83762332, 2.83762332, 2.83762332, 2.83762332, 2.83762332,\n",
       "         2.83762332, 2.83762332, 2.83762332, 2.83762332, 2.83762332,\n",
       "         2.83762332, 2.83762332, 2.83762332, 2.83762332],\n",
       "        [0.83762275, 0.83762275, 0.83762275, 0.83762275, 0.83762275,\n",
       "         0.83762275, 0.83762275, 0.83762275, 0.83762275, 0.83762275,\n",
       "         0.83762275, 0.83762275, 0.83762275, 0.83762275]]),\n",
       " array([[ 1.2380348 ,  1.2380348 ,  1.2380348 ,  1.2380348 ,  1.2380348 ,\n",
       "          1.2380348 ,  1.2380348 ,  1.2380348 ,  1.2380348 ,  1.2380348 ,\n",
       "          1.2380348 ,  1.2380348 ,  1.2380348 ,  1.2380348 ],\n",
       "        [-0.76196583, -0.76196583, -0.76196583, -0.76196583, -0.76196583,\n",
       "         -0.76196583, -0.76196583, -0.76196583, -0.76196583, -0.76196583,\n",
       "         -0.76196583, -0.76196583, -0.76196583, -0.76196583]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]]),\n",
       " array([[-0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163, -0.09801163,\n",
       "         -0.09801163, -0.09801163, -0.09801163, -0.09801163],\n",
       "        [-2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235, -2.09801235,\n",
       "         -2.09801235, -2.09801235, -2.09801235, -2.09801235]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
